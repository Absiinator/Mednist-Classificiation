{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRBt1VXNx0zi",
        "outputId": "4b82b27f-0d19-43dc-84c9-eee8caeaef31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: CUDA not found, CPU only.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as mp\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as om\n",
        "import torchvision as tv\n",
        "import torch.utils.data as dat\n",
        "\n",
        "if torch.cuda.is_available():     # Make sure GPU is available\n",
        "    dev = torch.device(\"cuda:0\")\n",
        "    kwar = {'num_workers': 8, 'pin_memory': True}\n",
        "    cpu = torch.device(\"cpu\")\n",
        "else:\n",
        "    print(\"Warning: CUDA not found, CPU only.\")\n",
        "    dev = torch.device(\"cpu\")\n",
        "    kwar = {}\n",
        "    cpu = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXJc5eSFyDad",
        "outputId": "fcc41d8a-2a7a-438c-ced9-e60dd43e8970"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 58954 images in 6 distinct categories\n",
            "Label names: ['Hand', 'BreastMRI', 'ChestCT', 'HeadCT', 'AbdomenCT', 'CXR']\n",
            "Label counts: [10000, 8954, 10000, 10000, 10000, 10000]\n",
            "Image dimensions: 64 x 64\n"
          ]
        }
      ],
      "source": [
        "dataDir = 'resized'               # The main data directory\n",
        "classNames = os.listdir(dataDir)  # Each type of image can be found in its own subdirectory\n",
        "numClass = len(classNames)        # Number of types = number of subdirectories\n",
        "imageFiles = [[os.path.join(dataDir,classNames[i],x) for x in os.listdir(os.path.join(dataDir,classNames[i]))]\n",
        "              for i in range(numClass)]                     # A nested list of filenames\n",
        "numEach = [len(imageFiles[i]) for i in range(numClass)]     # A count of each type of image\n",
        "imageFilesList = []               # Created an un-nested list of filenames\n",
        "imageClass = []                   # The labels -- the type of each individual image in the list\n",
        "for i in range(numClass):\n",
        "    imageFilesList.extend(imageFiles[i])\n",
        "    imageClass.extend([i]*numEach[i])\n",
        "numTotal = len(imageClass)        # Total number of images\n",
        "imageWidth, imageHeight = Image.open(imageFilesList[0]).size         # The dimensions of each image\n",
        "\n",
        "print(\"There are\",numTotal,\"images in\",numClass,\"distinct categories\")\n",
        "print(\"Label names:\",classNames)\n",
        "print(\"Label counts:\",numEach)\n",
        "print(\"Image dimensions:\",imageWidth,\"x\",imageHeight)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Cft1SakqyL-V"
      },
      "outputs": [],
      "source": [
        "toTensor = tv.transforms.ToTensor()\n",
        "def scaleImage(x):          # Pass a PIL image, return a tensor\n",
        "    y = toTensor(x)\n",
        "    if(y.min() < y.max()):  # Assuming the image isn't empty, rescale so its values run from 0 to 1\n",
        "        y = (y - y.min())/(y.max() - y.min()) \n",
        "    z = y - y.mean()        # Subtract the mean value of the image\n",
        "    return z\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMsS9hVQyZYB",
        "outputId": "f6bca613-f9c2-4d50-d8b3-2cf1bb86f160"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rescaled min pixel value = -0.786; Max = 0.972; Mean = -3.18e-09\n"
          ]
        }
      ],
      "source": [
        "imageTensor = torch.stack([scaleImage(Image.open(x)) for x in imageFilesList])  # Load, scale, and stack image (X) tensor\n",
        "classTensor = torch.tensor(imageClass)  # Create label (Y) tensor\n",
        "print(\"Rescaled min pixel value = {:1.3}; Max = {:1.3}; Mean = {:1.3}\"\n",
        "      .format(imageTensor.min().item(),imageTensor.max().item(),imageTensor.mean().item()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyIluv2Gya6u",
        "outputId": "69b01a97-5442-4e3a-e17e-5ddeace11be1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training images = 47214 Validation = 5802 Testing = 5938\n"
          ]
        }
      ],
      "source": [
        "validFrac = 0.1   # Define the fraction of images to move to validation dataset\n",
        "testFrac = 0.1    # Define the fraction of images to move to test dataset\n",
        "validList = []\n",
        "testList = []\n",
        "trainList = []\n",
        "\n",
        "for i in range(numTotal):\n",
        "    rann = np.random.random() # Randomly reassign images\n",
        "    if rann < validFrac:\n",
        "        validList.append(i)\n",
        "    elif rann < testFrac + validFrac:\n",
        "        testList.append(i)\n",
        "    else:\n",
        "        trainList.append(i)\n",
        "        \n",
        "nTrain = len(trainList)  # Count the number in each set\n",
        "nValid = len(validList)\n",
        "nTest = len(testList)\n",
        "print(\"Training images =\",nTrain,\"Validation =\",nValid,\"Testing =\",nTest)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1-OkJO_rydIH"
      },
      "outputs": [],
      "source": [
        "trainIds = torch.tensor(trainList)    # Slice the big image and label tensors up into\n",
        "validIds = torch.tensor(validList)    #       training, validation, and testing tensors\n",
        "testIds = torch.tensor(testList)\n",
        "trainX = imageTensor[trainIds,:,:,:]\n",
        "trainY = classTensor[trainIds]\n",
        "validX = imageTensor[validIds,:,:,:]\n",
        "validY = classTensor[validIds]\n",
        "testX = imageTensor[testIds,:,:,:]\n",
        "testY = classTensor[testIds]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kTDD1L9eyfCG"
      },
      "outputs": [],
      "source": [
        "class MedNet(nn.Module):\n",
        "    def __init__(self,xDim,yDim,numC): # Pass image dimensions and number of labels when initializing a model   \n",
        "        super(MedNet,self).__init__()  # Extends the basic nn.Module to the MedNet class\n",
        "        # The parameters here define the architecture of the convolutional portion of the CNN. Each image pixel\n",
        "        # has numConvs convolutions applied to it, and convSize is the number of surrounding pixels included\n",
        "        # in each convolution. Lastly, the numNodesToFC formula calculates the final, remaining nodes at the last\n",
        "        # level of convolutions so that this can be \"flattened\" and fed into the fully connected layers subsequently.\n",
        "        # Each convolution makes the image a little smaller (convolutions do not, by default, \"hang over\" the edges\n",
        "        # of the image), and this makes the effective image dimension decreases.\n",
        "        \n",
        "        numConvs1 = 10\n",
        "        convSize1 = 7\n",
        "        numConvs2 = 5\n",
        "        convSize2 = 14\n",
        "        numNodesToFC = numConvs2*(xDim-(convSize1-1)-(convSize2-1))*(yDim-(convSize1-1)-(convSize2-1))\n",
        "\n",
        "        # nn.Conv2d(channels in, channels out, convolution height/width)\n",
        "        # 1 channel -- grayscale -- feeds into the first convolution. The same number output from one layer must be\n",
        "        # fed into the next. These variables actually store the weights between layers for the model.\n",
        "        \n",
        "        self.cnv1 = nn.Conv2d(1, numConvs1, convSize1)\n",
        "        self.cnv2 = nn.Conv2d(numConvs1, numConvs2, convSize2)\n",
        "        \n",
        "        # These parameters define the number of output nodes of each fully connected layer.\n",
        "        # Each layer must output the same number of nodes as the next layer begins with.\n",
        "        # The final layer must have output nodes equal to the number of labels used.\n",
        "        \n",
        "        fcSize1 = 400\n",
        "        fcSize2 = 80\n",
        "        \n",
        "        # nn.Linear(nodes in, nodes out)\n",
        "        # Stores the weights between the fully connected layers\n",
        "        \n",
        "        self.ful1 = nn.Linear(numNodesToFC,fcSize1)\n",
        "        self.ful2 = nn.Linear(fcSize1, fcSize2)\n",
        "        self.ful3 = nn.Linear(fcSize2,numC)\n",
        "\n",
        "        # DROPOUTS\n",
        "        # Dropout is a technique that randomly sets a fraction of the nodes to zero. This is used to prevent overfitting\n",
        "        # and to prevent the model from memorizing the training data.\n",
        "        self.drop1 = nn.Dropout(p=0.4)\n",
        "        self.drop2 = nn.Dropout(p=0.8)\n",
        "\n",
        "        \n",
        "    def forward(self,x):\n",
        "        # This defines the steps used in the computation of output from input.\n",
        "        # It makes uses of the weights defined in the __init__ method.\n",
        "        # Each assignment of x here is the result of feeding the input up through one layer.\n",
        "        # Here we use the activation function elu, which is a smoother version of the popular relu function.\n",
        "        \n",
        "        x = F.elu(self.cnv1(x)) # Feed through first convolutional layer, then apply activation\n",
        "        x = F.elu(self.drop1(x)) # Apply dropout to the output of the convolutional layers\n",
        "        x = F.elu(self.cnv2(x)) # Feed through second convolutional layer, apply activation\n",
        "        x = F.elu(self.drop2(x)) # Apply dropout to the output of the convolutional layers\n",
        "        \n",
        "        x = x.view(-1,self.num_flat_features(x)) # Flatten convolutional layer into fully connected layer\n",
        "        x = F.elu(self.ful1(x)) # Feed through first fully connected layer, apply activation\n",
        "        x = F.elu(self.ful2(x)) # Feed through second FC layer, apply output\n",
        "        x = self.ful3(x)        # Final FC layer to output. No activation, because it's used to calculate loss\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):  # Count the individual nodes in a layer\n",
        "        size = x.size()[1:]\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "03CFVHLSyhkR"
      },
      "outputs": [],
      "source": [
        "model = MedNet(imageWidth,imageHeight,numClass).to(dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6_Wm_73yj79",
        "outputId": "18aa2da4-af28-47a1-94fe-5de0f8de5e8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch =   1; Training loss = 0.7775; Validation loss = 0.2542\n",
            "Epoch =   2; Training loss = 0.2296; Validation loss = 0.1785\n",
            "Epoch =   3; Training loss = 0.1716; Validation loss = 0.1295\n",
            "Epoch =   4; Training loss = 0.1332; Validation loss = 0.1202\n",
            "Epoch =   5; Training loss = 0.1078; Validation loss = 0.0959\n",
            "Epoch =   6; Training loss = 0.0884; Validation loss = 0.0710\n",
            "Epoch =   7; Training loss = 0.0741; Validation loss = 0.0891\n",
            "Epoch =   8; Training loss = 0.0652; Validation loss = 0.0686\n",
            "Epoch =   9; Training loss = 0.0589; Validation loss = 0.0678\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/jeffreylepage/Desktop/Medical-MNIST-Classification/MedNIST2.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jeffreylepage/Desktop/Medical-MNIST-Classification/MedNIST2.ipynb#ch0000009?line=29'>30</a>\u001b[0m     loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mcross_entropy(yOut, batY,weight\u001b[39m=\u001b[39mCEweights)        \u001b[39m# Compute loss\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jeffreylepage/Desktop/Medical-MNIST-Classification/MedNIST2.ipynb#ch0000009?line=30'>31</a>\u001b[0m     epochLoss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()      \u001b[39m# Add loss\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jeffreylepage/Desktop/Medical-MNIST-Classification/MedNIST2.ipynb#ch0000009?line=31'>32</a>\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()               \u001b[39m# Backpropagate loss\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jeffreylepage/Desktop/Medical-MNIST-Classification/MedNIST2.ipynb#ch0000009?line=32'>33</a>\u001b[0m     opti\u001b[39m.\u001b[39mstep()                   \u001b[39m# Update model weights using optimizer\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jeffreylepage/Desktop/Medical-MNIST-Classification/MedNIST2.ipynb#ch0000009?line=33'>34</a>\u001b[0m validLoss \u001b[39m=\u001b[39m \u001b[39m0.\u001b[39m\n",
            "File \u001b[0;32m~/miniforge3/envs/mnist/lib/python3.9/site-packages/torch/_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/jeffreylepage/miniforge3/envs/mnist/lib/python3.9/site-packages/torch/_tensor.py?line=297'>298</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///Users/jeffreylepage/miniforge3/envs/mnist/lib/python3.9/site-packages/torch/_tensor.py?line=298'>299</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    <a href='file:///Users/jeffreylepage/miniforge3/envs/mnist/lib/python3.9/site-packages/torch/_tensor.py?line=299'>300</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    <a href='file:///Users/jeffreylepage/miniforge3/envs/mnist/lib/python3.9/site-packages/torch/_tensor.py?line=300'>301</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/jeffreylepage/miniforge3/envs/mnist/lib/python3.9/site-packages/torch/_tensor.py?line=304'>305</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    <a href='file:///Users/jeffreylepage/miniforge3/envs/mnist/lib/python3.9/site-packages/torch/_tensor.py?line=305'>306</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> <a href='file:///Users/jeffreylepage/miniforge3/envs/mnist/lib/python3.9/site-packages/torch/_tensor.py?line=306'>307</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
            "File \u001b[0;32m~/miniforge3/envs/mnist/lib/python3.9/site-packages/torch/autograd/__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/jeffreylepage/miniforge3/envs/mnist/lib/python3.9/site-packages/torch/autograd/__init__.py?line=150'>151</a>\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/jeffreylepage/miniforge3/envs/mnist/lib/python3.9/site-packages/torch/autograd/__init__.py?line=151'>152</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m--> <a href='file:///Users/jeffreylepage/miniforge3/envs/mnist/lib/python3.9/site-packages/torch/autograd/__init__.py?line=153'>154</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(\n\u001b[1;32m    <a href='file:///Users/jeffreylepage/miniforge3/envs/mnist/lib/python3.9/site-packages/torch/autograd/__init__.py?line=154'>155</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    <a href='file:///Users/jeffreylepage/miniforge3/envs/mnist/lib/python3.9/site-packages/torch/autograd/__init__.py?line=155'>156</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "learnRate = 0.01          # Define a learning rate.\n",
        "maxEpochs = 50            # Maximum training epochs\n",
        "t2vRatio = 1.2              # Maximum allowed ratio of validation to training loss\n",
        "t2vEpochs = 2             # Number of consecutive epochs before halting if validation loss exceeds above limit\n",
        "batchSize = 300           # Batch size. Going too large will cause an out-of-memory error.\n",
        "trainBats = nTrain // batchSize       # Number of training batches per epoch. Round down to simplify last batch\n",
        "validBats = nValid // batchSize       # Validation batches. Round down\n",
        "testBats = -(-nTest // batchSize)     # Testing batches. Round up to include all\n",
        "CEweights = torch.zeros(numClass)     # This takes into account the imbalanced dataset.\n",
        "for i in trainY.tolist():             #      By making rarer images count more to the loss, \n",
        "    CEweights[i].add_(1)              #      we prevent the model from ignoring them.\n",
        "CEweights = 1. / CEweights.clamp_(min=1.)                     # Weights should be inversely related to count\n",
        "CEweights = (CEweights * numClass / CEweights.sum()).to(dev)  # The weights average to 1\n",
        "opti = om.SGD(model.parameters(), lr = learnRate)   # Initialize an optimizer\n",
        "CEweights = torch.ones(numClass).to(dev)\n",
        "\n",
        "\n",
        "validation_df = pd.DataFrame({'epoch':[],'epochLoss':[], 'validation_loss':[]})\n",
        "for i in range(maxEpochs):\n",
        "    model.train()                     # Set model to training mode\n",
        "    epochLoss = 0.\n",
        "    permute = torch.randperm(nTrain)  # Shuffle data to randomize batches\n",
        "    trainX = trainX[permute,:,:,:]\n",
        "    trainY = trainY[permute]\n",
        "    for j in range(trainBats):        # Iterate over batches\n",
        "        opti.zero_grad()              # Zero out gradient accumulated in optimizer\n",
        "        batX = trainX[j*batchSize:(j+1)*batchSize,:,:,:].to(dev)   # Slice shuffled data into batches\n",
        "        batY = trainY[j*batchSize:(j+1)*batchSize].to(dev)         # .to(dev) moves these batches to the GPU\n",
        "        yOut = model(batX)            # Evalute predictions\n",
        "        loss = F.cross_entropy(yOut, batY,weight=CEweights)        # Compute loss\n",
        "        epochLoss += loss.item()      # Add loss\n",
        "        loss.backward()               # Backpropagate loss\n",
        "        opti.step()                   # Update model weights using optimizer\n",
        "    validLoss = 0.\n",
        "    permute = torch.randperm(nValid)  # We go through the exact same steps, without backprop / optimization\n",
        "    validX = validX[permute,:,:,:]    # in order to evaluate the validation loss\n",
        "    validY = validY[permute]\n",
        "    model.eval()                      # Set model to evaluation mode\n",
        "    with torch.no_grad():             # Temporarily turn off gradient descent\n",
        "        for j in range(validBats):\n",
        "            opti.zero_grad()\n",
        "            batX = validX[j*batchSize:(j+1)*batchSize,:,:,:].to(dev)\n",
        "            batY = validY[j*batchSize:(j+1)*batchSize].to(dev)\n",
        "            yOut = model(batX)\n",
        "            validLoss += F.cross_entropy(yOut, batY,weight=CEweights).item()\n",
        "    epochLoss /= trainBats            # Average loss over batches and print\n",
        "    validLoss /= validBats\n",
        "    print(\"Epoch = {:-3}; Training loss = {:.4f}; Validation loss = {:.4f}\".format(i+1,epochLoss,validLoss))\n",
        "\n",
        "    a_df = pd.DataFrame({'epoch':[i+1],'epochLoss':[epochLoss], 'validation_loss':[validLoss]})\n",
        "    validation_df = pd.concat([validation_df,a_df])\n",
        "\n",
        "    if validLoss > t2vRatio * epochLoss:\n",
        "        t2vEpochs -= 1                # Test if validation loss exceeds halting threshold\n",
        "        if t2vEpochs < 1:\n",
        "            print(\"Validation loss too high; halting to prevent overfitting\")\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4uanRfsaGFCN"
      },
      "outputs": [],
      "source": [
        "epoch = validation_df['epoch'].values[-1].astype(int)\n",
        "\n",
        "learnRate = 0.001          # Define a learning rate.\n",
        "maxEpochs = 50            # Maximum training epochs\n",
        "t2vRatio = 1              # Maximum allowed ratio of validation to training loss\n",
        "t2vEpochs = 2             # Number of consecutive epochs before halting if validation loss exceeds above limit\n",
        "batchSize = 300           # Batch size. Going too large will cause an out-of-memory error.\n",
        "trainBats = nTrain // batchSize       # Number of training batches per epoch. Round down to simplify last batch\n",
        "validBats = nValid // batchSize       # Validation batches. Round down\n",
        "testBats = -(-nTest // batchSize)     # Testing batches. Round up to include all\n",
        "CEweights = torch.zeros(numClass)     # This takes into account the imbalanced dataset.\n",
        "for i in trainY.tolist():             #      By making rarer images count more to the loss, \n",
        "    CEweights[i].add_(1)              #      we prevent the model from ignoring them.\n",
        "CEweights = 1. / CEweights.clamp_(min=1.)                     # Weights should be inversely related to count\n",
        "CEweights = (CEweights * numClass / CEweights.sum()).to(dev)  # The weights average to 1\n",
        "opti = om.SGD(model.parameters(), lr = learnRate)   # Initialize an optimizer\n",
        "CEweights = torch.ones(numClass).to(dev)\n",
        "\n",
        "for i in range(maxEpochs):\n",
        "    model.train()                     # Set model to training mode\n",
        "    epochLoss = 0.\n",
        "    permute = torch.randperm(nTrain)  # Shuffle data to randomize batches\n",
        "    trainX = trainX[permute,:,:,:]\n",
        "    trainY = trainY[permute]\n",
        "    for j in range(trainBats):        # Iterate over batches\n",
        "        opti.zero_grad()              # Zero out gradient accumulated in optimizer\n",
        "        batX = trainX[j*batchSize:(j+1)*batchSize,:,:,:].to(dev)   # Slice shuffled data into batches\n",
        "        batY = trainY[j*batchSize:(j+1)*batchSize].to(dev)         # .to(dev) moves these batches to the GPU\n",
        "        yOut = model(batX)            # Evalute predictions\n",
        "        loss = F.cross_entropy(yOut, batY,weight=CEweights)        # Compute loss\n",
        "        epochLoss += loss.item()      # Add loss\n",
        "        loss.backward()               # Backpropagate loss\n",
        "        opti.step()                   # Update model weights using optimizer\n",
        "    validLoss = 0.\n",
        "    permute = torch.randperm(nValid)  # We go through the exact same steps, without backprop / optimization\n",
        "    validX = validX[permute,:,:,:]    # in order to evaluate the validation loss\n",
        "    validY = validY[permute]\n",
        "    model.eval()                      # Set model to evaluation mode\n",
        "    with torch.no_grad():             # Temporarily turn off gradient descent\n",
        "        for j in range(validBats):\n",
        "            opti.zero_grad()\n",
        "            batX = validX[j*batchSize:(j+1)*batchSize,:,:,:].to(dev)\n",
        "            batY = validY[j*batchSize:(j+1)*batchSize].to(dev)\n",
        "            yOut = model(batX)\n",
        "            validLoss += F.cross_entropy(yOut, batY,weight=CEweights).item()\n",
        "    epochLoss /= trainBats            # Average loss over batches and print\n",
        "    validLoss /= validBats\n",
        "    print(\"Epoch = {:-3}; Training loss = {:.4f}; Validation loss = {:.4f}\".format(epoch+1,epochLoss,validLoss))\n",
        "\n",
        "    a_df = pd.DataFrame({'epoch':[epoch+1],'epochLoss':[epochLoss], 'validation_loss':[validLoss]})\n",
        "    validation_df = pd.concat([validation_df,a_df])\n",
        "\n",
        "    if validLoss > t2vRatio * epochLoss:\n",
        "        t2vEpochs -= 1                # Test if validation loss exceeds halting threshold\n",
        "        if t2vEpochs < 1:\n",
        "            print(\"Validation loss too high; halting to prevent overfitting\")\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NkVblUODL4qM"
      },
      "outputs": [],
      "source": [
        "validation_df['epoch'] = validation_df['epoch'].astype(int)\n",
        "validation_df = validation_df.set_index('epoch')\n",
        "validation_df.tail(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PGcY0xgqzz68"
      },
      "outputs": [],
      "source": [
        "confuseMtx = np.zeros((numClass,numClass),dtype=int)    # Create empty confusion matrix\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    permute = torch.randperm(nTest)                     # Shuffle test data\n",
        "    testX = testX[permute,:,:,:]\n",
        "    testY = testY[permute]\n",
        "    for j in range(testBats):                           # Iterate over test batches\n",
        "        batX = testX[j*batchSize:(j+1)*batchSize,:,:,:].to(dev)\n",
        "        batY = testY[j*batchSize:(j+1)*batchSize].to(dev)\n",
        "        yOut = model(batX)                              # Pass test batch through model\n",
        "        pred = yOut.max(1,keepdim=True)[1]              # Generate predictions by finding the max Y values\n",
        "        for j in torch.cat((batY.view_as(pred), pred),dim=1).tolist(): # Glue together Actual and Predicted to\n",
        "            confuseMtx[j[0],j[1]] += 1                  # make (row, col) pairs, and increment confusion matrix\n",
        "correct = sum([confuseMtx[i,i] for i in range(numClass)])   # Sum over diagonal elements to count correct predictions\n",
        "print(\"Correct predictions: \",correct,\"of\",nTest, '=', f'{100.*correct/nTest:.2f}',\"%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "G1wNnUhVz5YL"
      },
      "outputs": [],
      "source": [
        "def scaleBack(x):               # Pass a tensor, return a numpy array from 0 to 1\n",
        "    if(x.min() < x.max()):      # Assuming the image isn't empty, rescale so its values run from 0 to 1\n",
        "        x = (x - x.min())/(x.max() - x.min())\n",
        "    return x[0].to(cpu).numpy() # Remove channel (grayscale anyway)\n",
        "\n",
        "model.eval()\n",
        "mp.subplots(3,3,figsize=(8,8))\n",
        "imagesLeft = 9\n",
        "permute = torch.randperm(nTest)        # Shuffle test data\n",
        "testX = testX[permute,:,:,:]\n",
        "testY = testY[permute]\n",
        "for j in range(testBats):              # Iterate over test batches\n",
        "    batX = testX[j*batchSize:(j+1)*batchSize,:,:,:].to(dev)\n",
        "    batY = testY[j*batchSize:(j+1)*batchSize].to(dev)\n",
        "    yOut = model(batX)                 # Pass test batch through model\n",
        "    pred = yOut.max(1)[1].tolist()     # Generate predictions by finding the max Y values\n",
        "    for i, y in enumerate(batY.tolist()):\n",
        "        if imagesLeft and y != pred[i]:         # Compare the actual y value to the prediction\n",
        "            imagesLeft -= 1\n",
        "            mp.subplot(3,3,9-imagesLeft)\n",
        "            mp.xlabel(classNames[pred[i]])      # Label image with what the model thinks it is\n",
        "            mp.imshow(scaleBack(batX[i]),cmap='gray',vmin=0,vmax=1)\n",
        "\n",
        "mp.tight_layout()\n",
        "mp.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ahvGSTix1eMR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "MedNIST.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
